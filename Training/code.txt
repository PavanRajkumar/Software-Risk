# Author : Richard Delwin Myloth


gitvc.py
line no : end

# print("\n>> Mapping Authors <<\n")
# authors = features.Authors(data, "author")
# resp = authors.map_author_to_val()
# print(resp)
# Training a kmeans model
# data.drop(columns=["commit id", "date"], axis=1, inplace=True)
#
# for column_names in data.columns:
#     data[column_names] = pd.to_numeric(data[column_names])
#
# z = np.abs(stats.zscore(data))
# threshold = 3
# print(np.where(z > threshold))
# print(data.shape)
# indexes, rows = np.where(z > threshold)
# indexes = list(set(indexes))
# for ind in indexes:
#     data.drop(data.index[ind], inplace=True)
# print(data.shape)
# data = data.reset_index()
#
# scaler = MinMaxScaler()
#
# X_scaled = scaler.fit_transform(data)
#
# kmeans = KMeans(n_clusters=3, max_iter=600, algorithm='auto', init='random', random_state=40)
# kmeans.fit(X_scaled)
# print(scaler.datamax_, scaler.datamin_)



git_cmd
line no :33

def get_git_log(commit=None):

    if commit is not None:
        bash_cmd = \
            'git --no-pager log --stat -1 {commit}'.format(commit=commit)
    else:
        bash_cmd = 'git --no-pager log --stat'

    stdout = run_bash_command(bash_cmd)

    return stdout


parsing.py
line no: 9

def split_commits(whole_log):

    lines = whole_log.splitlines()

    # find the indices which separate each commit's entry
    commit_line_idxs = [i for i, line in enumerate(lines)
                        if re.match(r'^commit \w{40}$', line)]

    # split the lines from the whole log into subsets for each log entry
    commit_lines = np.array_split(lines, commit_line_idxs)

    return ["\n".join(arr) for arr in commit_lines[1:]]


def parse_commit(commit_str):

    feats = defaultdict(lambda: None)
    lines = commit_str.splitlines()

    # parse the commit line
    commit_line = [line for line in lines if line.startswith('commit')][0]
    feats['hash'] = \
        trim_hash(re.match(r'commit (\w{40})', commit_line).group(1))

    # NOTE: skip string features for now because the one-hot encoding is a pain
    # parse the author line
    # author_line = [line for line in lines if line.startswith('Author:')][0]
    # author_matches = re.match(r'Author: (.+) <(.+)>', author_line)
    # feats['user'] = author_matches.group(1)
    # feats['email'] = author_matches.group(2)

    # parse the date line
    time_line = [line for line in lines if line.startswith('Date:')][0]
    timestamp = re.match(r'Date: (.*)', time_line).group(1)
    created_at = pd.to_datetime(timestamp, utc=True).tz_convert('US/Central')
    feats['dayofweek'] = created_at.dayofweek
    feats['hour'] = created_at.hour

    # parse the body lines
    body_lines = [line.lstrip() for line in lines if line.startswith('    ')]
    feats['len_message'] = len('\n'.join(body_lines))

    # NOTE: skip string features for now because the one-hot encoding is a pain
    # feats['tag'] = body_lines[0].split()[0].rstrip(':')

    # if this is a merge commit fill some fields with NaNs
    if any([line.startswith('Merge:') for line in lines]):
        # feats['tag'] = 'MERGE'
        feats['changed_files'] = np.NaN
        feats['additions'] = np.NaN
        feats['deletions'] = np.NaN

        return feats

    # parse the changes line
    changes_line = lines[-1]

    changed_regex = r' ([0-9]+) file[s]{0,1} changed'
    insert_regex = r'.* ([0-9]+) insertion[s]{0,1}'
    delete_regex = r'.* ([0-9]+) deletion[s]{0,1}'

    if re.match(changed_regex, changes_line):
        feats['changed_files'] = \
                int(re.match(changed_regex, changes_line).group(1))

    if re.match(insert_regex, changes_line):
        feats['additions'] = int(re.match(insert_regex, changes_line).group(1))

    if re.match(delete_regex, changes_line):
        feats['deletions'] = int(re.match(delete_regex, changes_line).group(1))

    return feats


def get_features(commit=None):
    logstr = get_git_log(commit)

    feats = pd.DataFrame([parse_commit(c) for c in split_commits(logstr)])

    feats = feats.set_index('hash').fillna(0)

    return feats


